import numpy as np
import pandas as pd
import csv
import random
from sklearn.utils import shuffle
from sklearn.neighbors import KNeighborsClassifier
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler, normalize
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.svm import SVC
from sklearn.grid_search import GridSearchCV
from sklearn.preprocessing import Imputer
%pylab inline --no-import-all



#处理Traindata
def loadtraindata():
    i=pd.read_csv('train.csv',header=0)   
    a=i.describe()
    index=['count','mean','std','min','25%','50%','75%','max']
    a.to_csv('train_describe.csv', header = True, index=index)
    #处理缺失值
    imp_median = Imputer(missing_values='NaN', strategy='median', axis=1)
    imp_most_frequent = Imputer(missing_values='NaN', strategy='most_frequent', axis=1)
    i['Age'] = pd.DataFrame(dict(Age = (imp_median.fit_transform(i['Age']))[0]))
    i['Sex']= [1 if x == 'female' else 0 for x in i['Sex']]
    
    a=[]
    for x in i['Embarked']:
        if x == 'C':
            x=0
        elif x == 'Q':
            x=1
        else:
            x=2
        a.append(x)
    i['Embarked']=pd.DataFrame(dict(Embarked=a))
    i['Embarked']= pd.DataFrame(dict(Embarked = (imp_most_frequent.fit_transform(i['Embarked']))[0]))
    
    i=np.asarray(i)
    i=np.delete(i,[3,8,10],1)
    m,n=np.shape(i)
    x=i[:,0:2]
    i=i[:,2:]
    x,i=shuffle(x,i)
    Trainlabel=x[:,1]
    Traindata=i
    print Trainlabel.shape,Traindata.shape
    return Trainlabel,Traindata


#处理Testdata
def loadtestdata():
    i=pd.read_csv('test.csv',header=0)
    imp_median = Imputer(missing_values='NaN', strategy='median', axis=1)
    imp_most_frequent = Imputer(missing_values='NaN', strategy='most_frequent', axis=1)
    imp_most_frequent = Imputer(missing_values='NaN', strategy='mean', axis=1)
    i['Age'] = pd.DataFrame(dict(Age = (imp_median.fit_transform(i['Age']))[0]))
    i['Fare'] = pd.DataFrame(dict(Fare = (imp_median.fit_transform(i['Fare']))[0]))
    i['Sex']= [1 if x == 'female' else 0 for x in i['Sex']]
    
    a=[]
    for x in i['Embarked']:
        if x == 'C':
            x=0
        elif x == 'Q':
            x=1
        else:
            x=2
        a.append(x)
    i['Embarked']=pd.DataFrame(dict(Embarked=a))
    i['Embarked']= pd.DataFrame(dict(Embarked = (imp_most_frequent.fit_transform(i['Embarked']))[0]))

    Testdata=np.asarray(i)
    Testdata=np.delete(Testdata,[0,2,7,9],1)
    print Testdata.shape
    return Testdata

            
Trainlabel,Traindata=loadtraindata()
Testdata=loadtestdata()

#归一化
ss = StandardScaler()
ss.fit_transform(Traindata)
Traindata=ss.transform(Traindata)
Testdata=ss.transform(Testdata)


#主成分分析
pca=PCA()
pca.fit(np.r_[Testdata,Traindata])
pd.DataFrame(pca.explained_variance_ratio_).plot(kind='bar')
n_components=np.where(np.cumsum(pca.explained_variance_ratio_)>=0.99)[0][0]
print n_components
print  np.shape(Traindata),np.shape(Testdata)

#降维
pca=PCA(n_components=n_components)
pca.fit(np.r_[Testdata,Traindata])
Traindata=pca.transform(Traindata)
Testdata=pca.transform(Testdata)
print  np.shape(Traindata),np.shape(Testdata)

##特征提取
## filter features by forest model
trees = ExtraTreesClassifier(n_estimators=100)
trees.fit(Traindata, Trainlabel)
pd.DataFrame(trees.feature_importances_).plot(kind='bar')
selected_features = np.where(trees.feature_importances_ > 0.005)[0]
Traindata = Traindata[:, selected_features]
print  np.shape(Traindata),np.shape(Testdata)

#使用搜索算法查找最优参数
svc = SVC(probability=True)
gammas = [1e-4, 3e-4, 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1., 3., 10.]
gs = GridSearchCV(svc, {'gamma': gammas}, scoring = 'accuracy', cv = 10, n_jobs=-1)
gs.fit(Traindata, Trainlabel)
print gs.best_params_
print gs.best_score_

svc = SVC(probability=True, **gs.best_params_)
svc.fit(Traindata, Trainlabel)
print(svc)

Trainlabel_predict=svc.predict(Testdata)

#保存数据
Trainlabel_predict_df = pd.DataFrame(dict(PassengerId = np.arange(892, Trainlabel_predict.shape[0]+892), Survived=Trainlabel_predict))
Trainlabel_predict_df.to_csv('submission.csv', header = True, index=False)